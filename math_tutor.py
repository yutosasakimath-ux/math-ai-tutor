import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. ã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
st.set_page_config(page_title="æ•°å­¦AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ Pro", page_icon="ğŸ“", layout="wide")

st.title("ğŸ“ é«˜æ ¡æ•°å­¦ AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ Pro")
st.caption("ã‚ã‹ã‚‰ãªã„å•é¡Œã‚’è³ªå•ã—ã¦ã¿ã‚ˆã†ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã§ã€Œé¡é¡Œã€ã‚‚å‡ºã›ã‚‹ã‚ˆï¼")

# --- 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("ğŸ› ï¸ å…ˆç”Ÿç”¨ãƒ»ãƒ„ãƒ¼ãƒ«")
    
    # APIã‚­ãƒ¼è¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    api_key = ""
    try:
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("âœ… èªè¨¼æ¸ˆã¿ï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ¼ï¼‰")
    except:
        pass

    if not api_key:
        api_key = st.text_input("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›", type="password")

    st.markdown("---")

    # ä¼šè©±ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹", type="primary"):
        st.session_state.messages = [] 
        st.rerun() 

    # é¡é¡Œç”Ÿæˆãƒœã‚¿ãƒ³
    if st.button("ğŸ”„ ã•ã£ãã®é¡é¡Œã‚’å‡ºé¡Œ"):
        st.session_state.messages.append({
            "role": "user", 
            "content": "ã•ã£ãã®è§£èª¬ã‚’è¸ã¾ãˆã¦ã€æ•°å€¤ã‚„è¨­å®šã‚’å¤‰ãˆãŸã€é¡é¡Œã€‘ã‚’1å•ä½œæˆã—ã¦ãã ã•ã„ã€‚ã¾ã ç­”ãˆã¯è¨€ã‚ãªã„ã§ãã ã•ã„ã€‚"
        })
        st.rerun() 

    st.markdown("---")
    
    # ãƒ­ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    log_text = ""
    for m in st.session_state.messages:
        role_name = "è‡ªåˆ†" if m["role"] == "user" else "AIå…ˆç”Ÿ"
        content_text = m["content"] if isinstance(m["content"], str) else "[ç”»åƒ]"
        log_text += f"ã€{role_name}ã€‘\n{content_text}\n\n"
    st.download_button("ãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.txt)", log_text, "math_log.txt")

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    with st.expander("å…ˆç”Ÿç”¨ï¼šæŒ‡å°æ–¹é‡"):
        system_instruction = st.text_area(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹",
            value="""
            ã‚ãªãŸã¯æ—¥æœ¬ã®é«˜æ ¡ã®è¦ªåˆ‡ã§å„ªç§€ãªæ•°å­¦æ•™å¸«ã§ã™ã€‚
            ç”Ÿå¾’ã‹ã‚‰ã®æ•°å­¦ã®è³ªå•ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯ç”»åƒï¼‰ã«ç­”ãˆã¦ãã ã•ã„ã€‚
            
            ã€æŒ‡å°ã®ãƒ«ãƒ¼ãƒ«ã€‘
            1. **ã™ãã«æ­£è§£ã‚’æ•™ãˆãªã„**ã€‚ãƒ’ãƒ³ãƒˆã‚’å‡ºã—ã¦è€ƒãˆã•ã›ã‚‹ã€‚
            2. ç”»åƒãŒé€ã‚‰ã‚ŒãŸå ´åˆã€ãã®å•é¡Œã®å†…å®¹ã‚’èª­ã¿å–ã£ã¦è§£èª¬ã™ã‚‹ã€‚
            3. æ•°å¼ã¯LaTeXå½¢å¼ï¼ˆ$ãƒãƒ¼ã‚¯ï¼‰ã‚’ä½¿ã£ã¦ç¶ºéº—ã«è¡¨ç¤ºã™ã‚‹ã€‚
            4. ç”Ÿå¾’ã‚’åŠ±ã¾ã—ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œã†ã€‚
            5. ã€Œé¡é¡Œã€ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸã‚‰ã€ç›´å‰ã®å•é¡Œã¨ä¼¼ãŸé›£æ˜“åº¦ã®å•é¡Œã‚’1å•ä½œæˆã™ã‚‹ã€‚
            """
        )

# --- 4. ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆå®‰å…¨ç­–ï¼šå®Ÿé¨“ãƒ¢ãƒ‡ãƒ«ã‚’é™¤å¤–ã—ã¦è‡ªå‹•é¸æŠï¼‰ ---
model = None
if api_key:
    genai.configure(api_key=api_key)
    try:
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å…¨å–å¾—
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # ã€ã“ã“ãŒé‡è¦ã€‘ç„¡æ–™æ ã®ãªã„å®Ÿé¨“ãƒ¢ãƒ‡ãƒ«(exp)ã‚„æœ€æ–°ã™ãã‚‹ãƒ¢ãƒ‡ãƒ«(2.5)ã‚’é™¤å¤–ã™ã‚‹
        stable_models = [m for m in all_models if "exp" not in m and "2.5" not in m]
        
        target_model = "gemini-1.5-flash" # ç¬¬ä¸€å¸Œæœ›
        
        if stable_models:
            # 1. "flash" ãŒã¤ãå®‰å®šãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™
            flash_model = next((m for m in stable_models if "flash" in m), None)
            # 2. ãªã‘ã‚Œã° "pro" ãŒã¤ãå®‰å®šãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™
            pro_model = next((m for m in stable_models if "pro" in m), None)
            
            # å„ªå…ˆé †ä½ï¼šFlash > Pro > ãƒªã‚¹ãƒˆã®æœ€åˆ
            if flash_model:
                target_model = flash_model
            elif pro_model:
                target_model = pro_model
            else:
                target_model = stable_models[0]
        
        # ãƒ¢ãƒ‡ãƒ«æ±ºå®š
        model = genai.GenerativeModel(
            model_name=target_model, 
            system_instruction=system_instruction
        )
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«å°‘ã—ã ã‘æƒ…å ±ã‚’å‡ºã™ï¼ˆå¿…è¦ãªã‘ã‚Œã°æ¶ˆã—ã¦OKï¼‰
        # st.sidebar.caption(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {target_model}")
        
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")

# --- 5. ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        content = message["content"]
        if isinstance(content, str):
            st.markdown(content)
        elif isinstance(content, dict) and "image" in content:
            st.image(content["image"], width=300)
            if "text" in content:
                st.markdown(content["text"])

# --- 6. AIå¿œç­”ãƒ­ã‚¸ãƒƒã‚¯ ---
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    if not api_key:
        with st.chat_message("assistant"):
            st.warning("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        try:
            last_msg = st.session_state.messages[-1]["content"]
            content_to_send = [last_msg["text"], last_msg["image"]] if isinstance(last_msg, dict) else last_msg

            try:
                response = model.generate_content(content_to_send, stream=True)
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        response_placeholder.markdown(full_response)
                
                st.session_state.messages.append({"role": "model", "content": full_response})
                st.rerun()
            
            except Exception as api_error:
                st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {api_error}")
                st.info("æ™‚é–“ã‚’ç½®ãã‹ã€ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")

        except Exception as e:
            st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")

# --- 7. å…¥åŠ›ã‚¨ãƒªã‚¢ ---
uploaded_file = st.file_uploader("ğŸ“¸ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰", type=["jpg", "png", "jpeg"], key="img_uploader")

if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›..."):
    if uploaded_file:
        img = Image.open(uploaded_file)
        st.session_state.messages.append({"role": "user", "content": {"text": prompt, "image": img}})
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()
