import streamlit as st
import google.generativeai as genai

# --- 1. ã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
st.set_page_config(page_title="æ•°å­¦AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼", page_icon="ğŸ“")

st.title("ğŸ“ é«˜æ ¡æ•°å­¦ AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼")
st.caption("Gemini 2.5 Flash æ­è¼‰ã€‚æœ€æ–°AIãŒã‚ãªãŸã®å­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼")

# --- 2. ä¼šè©±å±¥æ­´ã®ä¿å­˜å ´æ‰€ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("å…ˆç”Ÿç”¨ç®¡ç†ç”»é¢")
    
    # APIã‚­ãƒ¼è¨­å®š
    api_key = ""
    try:
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("âœ… èªè¨¼æ¸ˆã¿ï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ¼ä½¿ç”¨ä¸­ï¼‰")
    except:
        pass

    if not api_key:
        input_key = st.text_input("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›", type="password")
        if input_key:
            api_key = input_key.strip()
    
    st.markdown("---")

    # â˜…æ©Ÿèƒ½1ï¼šä¼šè©±ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ï¼ˆèµ¤è‰²ï¼‰â˜…
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹", type="primary"):
        st.session_state.messages = []
        st.rerun()

    # â˜…æ©Ÿèƒ½2ï¼šé¡é¡Œå‡ºé¡Œãƒœã‚¿ãƒ³ï¼ˆé€šå¸¸è‰²ï¼‰â˜…
    # æŠ¼ã™ã¨ã€è£å´ã§ã€Œé¡é¡Œã‚’ä½œã£ã¦ã€ã¨ã„ã†æŒ‡ç¤ºã‚’AIã«é€ã‚Šã¾ã™
    if st.button("ğŸ”„ ã•ã£ãã®é¡é¡Œã‚’å‡ºé¡Œ"):
        # AIã¸ã®æŒ‡ç¤ºå†…å®¹
        prompt_text = """
        ã€æ•™å¸«ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€‘
        ç›´å‰ã®ã‚„ã‚Šå–ã‚Šã§æ‰±ã£ãŸå•é¡Œã¨ã€ŒåŒã˜å˜å…ƒã€ã€ŒåŒã˜é›£æ˜“åº¦ã€ã®é¡é¡Œã‚’1å•ä½œæˆã—ã¦ãã ã•ã„ã€‚
        æ•°å€¤ã‚’å¤‰ãˆã‚‹ã ã‘ã§ãªãã€æœ¬è³ªçš„ãªç†è§£ã‚’è©¦ã™å•é¡Œã«ã—ã¦ãã ã•ã„ã€‚
        ã¾ã è§£èª¬ã¯ã›ãšã€å•é¡Œã®ã¿ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
        """
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã¨ã—ã¦å±¥æ­´ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": prompt_text})
        st.rerun()  # ç”»é¢ã‚’æ›´æ–°ã—ã¦AIã«ç­”ãˆã•ã›ã‚‹
    
    st.markdown("---")
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæŒ‡å°æ–¹é‡ï¼‰
    system_instruction = """
    ã‚ãªãŸã¯æ—¥æœ¬ã®é«˜æ ¡ã®è¦ªåˆ‡ã§å„ªç§€ãªæ•°å­¦æ•™å¸«ã§ã™ã€‚
    ç”Ÿå¾’ã‹ã‚‰ã®æ•°å­¦ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
    
    ã€æŒ‡å°ã®ãƒ«ãƒ¼ãƒ«ã€‘
    1. **ã™ãã«æœ€çµ‚çš„ãªæ­£è§£ã‚’æ•™ãˆãªã„ã“ã¨**ã€‚
    2. ç”Ÿå¾’ãŒè‡ªåŠ›ã§è§£ã‘ã‚‹ã‚ˆã†ã«ã€æ®µéšçš„ãªãƒ’ãƒ³ãƒˆã‚„ã€è€ƒãˆæ–¹ã®é“ç­‹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
    3. ç”Ÿå¾’ãŒé–“é•ãˆã¦ã„ã‚‹å ´åˆã¯ã€å¦å®šã›ãšã€Œæƒœã—ã„ï¼ã€ã€Œã“ã“ã‚’ç¢ºèªã—ã¦ã¿ã¦ã€ã¨åŠ±ã¾ã—ã¦ãã ã•ã„ã€‚
    4. æ•°å¼ã¯LaTeXå½¢å¼ï¼ˆ$ãƒãƒ¼ã‚¯ã§å›²ã‚€ï¼‰ã‚’ä½¿ã£ã¦ç¶ºéº—ã«è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚
    5. è§£èª¬ã¯é«˜æ ¡ç”Ÿã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„å¹³æ˜“ãªè¨€è‘‰ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
    6. ã€Œé¡é¡Œã€ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸã‚‰ã€ç›´å‰ã®å•é¡Œã®æ§‹é€ ã‚’åˆ†æã—ã€é©åˆ‡ãªç·´ç¿’å•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    """

# --- 4. ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
if api_key:
    genai.configure(api_key=api_key)
    
    try:
        # æœ€æ–°ãƒ¢ãƒ‡ãƒ«æŒ‡å®š
        target_model_name = "gemini-2.5-flash"
        
        model = genai.GenerativeModel(
            model_name=target_model_name,
            system_instruction=system_instruction
        )

        # é–‹ç™ºè€…ç”¨ãƒ¢ãƒ‡ãƒ«è¡¨ç¤º
        st.sidebar.divider()
        st.sidebar.caption("ğŸ› ï¸ Developer Info")
        st.sidebar.info(f"ğŸ¤– Active Model:\n`{target_model_name}`")

    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

# --- 5. éå»ã®ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤º ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. AIå¿œç­”ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒœã‚¿ãƒ³ã‹ã‚‰ã‚‚å…¥åŠ›æ¬„ã‹ã‚‰ã‚‚å…±é€šã§å‹•ãï¼‰ ---
# å±¥æ­´ã®æœ€å¾ŒãŒã€Œuserã€ãªã‚‰ã€AIãŒç­”ãˆã‚‹ç•ªã§ã™
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    
    if not api_key:
        st.warning("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„")
        st.stop()

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        try:
            # éå»ã®ä¼šè©±å±¥æ­´ã‚’AIã«æ¸¡ã™
            chat_history_for_ai = [
                {"role": m["role"], "parts": [m["content"]]} 
                for m in st.session_state.messages 
                if m["role"] != "system"
            ]
            
            # ãƒãƒ£ãƒƒãƒˆé–‹å§‹
            chat = model.start_chat(history=chat_history_for_ai)
            
            # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¾ãŸã¯ãƒœã‚¿ãƒ³ã®æŒ‡ç¤ºï¼‰ã‚’å–å¾—ã—ã¦é€ä¿¡
            last_msg = st.session_state.messages[-1]["content"]
            response = chat.send_message(last_msg, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    response_placeholder.markdown(full_response)
            
            # AIã®å›ç­”ã‚’ä¿å­˜
            st.session_state.messages.append({"role": "model", "content": full_response})
            
            # å®Œäº†å¾Œã«ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆé€£æ‰“é˜²æ­¢ï¼‰
            st.rerun()

        except Exception as e:
            err_msg = str(e)
            if "429" in err_msg:
                 st.error("âš ï¸ åˆ©ç”¨åˆ¶é™ï¼ˆ429ã‚¨ãƒ©ãƒ¼ï¼‰ã€‚å°‘ã—æ™‚é–“ã‚’ç½®ã„ã¦ãã ã•ã„ã€‚")
            elif "404" in err_msg:
                 st.error(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_model_name}")
            else:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- 7. å…¥åŠ›ã‚¨ãƒªã‚¢ ---
# â€»AIãŒå›ç­”ä¸­ã®æ™‚ã¯å…¥åŠ›æ¬„ã‚’å‡ºã•ãªã„ï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼‰
if not (st.session_state.messages and st.session_state.messages[-1]["role"] == "user"):
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šãƒ™ã‚¯ãƒˆãƒ«ã®å†…ç©ã£ã¦ä½•ï¼Ÿï¼‰"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¡¨ç¤º
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()
